{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiview.datasets.base import load_UCImultifeature\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_UCImultifeature()\n",
    "for ind in range(len(data)):\n",
    "    data[ind] = data[ind].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_laplacian(weights, d_mat):\n",
    "    #print(d_mat)\n",
    "    for ind in range(d_mat.shape[0]):\n",
    "        if(d_mat[ind, ind] != 0):\n",
    "            #print(np.sqrt(d_mat[ind, ind]))\n",
    "            d_mat[ind, ind] = 1 / np.sqrt(d_mat[ind, ind])\n",
    "    laplacian = np.eye(weights.shape[0])  - d_mat @ weights @ d_mat\n",
    "\n",
    "    return laplacian\n",
    "\n",
    "def comp_affinity(data, slt_indices, other_indices ):\n",
    "    \n",
    "    print(data)\n",
    "    slt = data[slt_indices]\n",
    "    raw = data[other_indices]\n",
    "    num_samples = data.shape[0]\n",
    "    affinity = rbf_kernel(raw, slt)\n",
    "    indices = np.argsort(affinity, axis = 1)[:, :-8]\n",
    "    for ind in range(affinity.shape[0]):\n",
    "        affinity[ind, indices[ind]] = 0\n",
    "    affinity /= np.sum(affinity, axis = 1).reshape(-1, 1)\n",
    "    zero_block1 = np.zeros((affinity.shape[0],affinity.shape[0]))\n",
    "    zero_block2 = np.zeros((affinity.shape[1], affinity.shape[1]))\n",
    "    top_half = np.hstack((zero_block1, affinity))\n",
    "    bot_half = np.hstack((affinity.T, zero_block2))\n",
    "    weight = np.vstack((top_half, bot_half))\n",
    "\n",
    "    D_mat = np.concatenate((np.sum(affinity, axis=1), \n",
    "                            np.sum(affinity.T, axis=1)))\n",
    "    D_mat = np.diag(D_mat)\n",
    "    return weight, D_mat\n",
    "    \n",
    "def get_salient(data, n_slt):\n",
    "    kmeans= KMeans(n_clusters = n_slt)\n",
    "    cat_data = np.hstack(data)\n",
    "    kmeans.fit(cat_data)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    dists = cdist(centroids, cat_data)\n",
    "    indices = np.argsort(dists, axis = 1)[:, 0]\n",
    "    indices = indices.flatten()\n",
    "    other_indices = set(list(range(data[0].shape[0]))).difference(indices)\n",
    "    other_indices = np.array(list(other_indices))\n",
    "    \n",
    "    #slt_pts = list()\n",
    "    #for k in range(len(data)):\n",
    "    #    slt_pts.append(data[k][indices])\n",
    "    return indices, other_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(v_data, n_clusters, n_slt = 40, r = 0.5, n_iter = 10):\n",
    "    \n",
    "    #Select salient points\n",
    "    slt_inds, other_inds = get_salient(v_data, n_slt)\n",
    "    \n",
    "    laplacians = list()\n",
    "\n",
    "    weight, d_mat = comp_affinity(v_data[1], slt_inds, other_inds)\n",
    "    print(d_mat)\n",
    "    laplacians.append(comp_laplacian(weight, d_mat))\n",
    "    \n",
    "    #for view in range(len(v_data)):\n",
    "    #    weight, d_mat = comp_affinity(v_data[view], slt_inds, other_inds)\n",
    "    #    laplacians.append(comp_laplacian(weight, d_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98. 236. 531. ...  15.  12.  13.]\n",
      " [121. 193. 607. ...  13.  15.  11.]\n",
      " [115. 141. 590. ...  14.  13.   6.]\n",
      " ...\n",
      " [337. 299. 852. ...  15.  17.  21.]\n",
      " [247. 261. 866. ...  13.  15.  15.]\n",
      " [355. 379. 867. ...  12.  12.  20.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[nan  0.  0. ...  0.  0.  0.]\n",
      " [ 0. nan  0. ...  0.  0.  0.]\n",
      " [ 0.  0. nan ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... nan  0.  0.]\n",
      " [ 0.  0.  0. ...  0. nan  0.]\n",
      " [ 0.  0.  0. ...  0.  0. nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "clusters = spectral_clustering(data, n_clusters = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
