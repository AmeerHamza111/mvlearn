{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Co-regression with co-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        nan  0.01010101         nan  0.03030303         nan  0.05050505\n",
      "         nan  0.07070707         nan  0.09090909         nan  0.11111111\n",
      "         nan  0.13131313         nan  0.15151515         nan  0.17171717\n",
      "         nan  0.19191919         nan  0.21212121         nan  0.23232323\n",
      "         nan  0.25252525         nan  0.27272727         nan  0.29292929\n",
      "         nan  0.31313131         nan  0.33333333         nan  0.35353535\n",
      "         nan  0.37373737         nan  0.39393939         nan  0.41414141\n",
      "         nan  0.43434343         nan  0.45454545         nan  0.47474747\n",
      "         nan  0.49494949         nan  0.51515152         nan  0.53535354\n",
      "         nan  0.55555556         nan  0.57575758         nan  0.5959596\n",
      "         nan  0.61616162         nan  0.63636364         nan  0.65656566\n",
      "         nan  0.67676768         nan  0.6969697          nan  0.71717172\n",
      "         nan  0.73737374         nan  0.75757576         nan  0.77777778\n",
      "         nan  0.7979798          nan  0.81818182         nan  0.83838384\n",
      "         nan  0.85858586         nan  0.87878788         nan  0.8989899\n",
      "         nan  0.91919192         nan  0.93939394         nan  0.95959596\n",
      "         nan  0.97979798         nan  1.        ]\n",
      "here\n",
      "starting\n",
      "50\n",
      "40\n",
      "unlabeled pool\n",
      "[14, 98, 22, 36, 86, 44, 16, 90, 30, 80]\n",
      "labeled\n",
      "[[  1.01010101e-02   1.00505051e+01]\n",
      " [  3.03030303e-02   1.01515152e+01]\n",
      " [  5.05050505e-02   1.02525253e+01]\n",
      " [  7.07070707e-02   1.03535354e+01]\n",
      " [  9.09090909e-02   1.04545455e+01]\n",
      " [  1.11111111e-01   1.05555556e+01]\n",
      " [  1.31313131e-01   1.06565657e+01]\n",
      " [  1.51515152e-01   1.07575758e+01]\n",
      " [  1.71717172e-01   1.08585859e+01]\n",
      " [  1.91919192e-01   1.09595960e+01]\n",
      " [  2.12121212e-01   1.10606061e+01]\n",
      " [  2.32323232e-01   1.11616162e+01]\n",
      " [  2.52525253e-01   1.12626263e+01]\n",
      " [  2.72727273e-01   1.13636364e+01]\n",
      " [  2.92929293e-01   1.14646465e+01]\n",
      " [  3.13131313e-01   1.15656566e+01]\n",
      " [  3.33333333e-01   1.16666667e+01]\n",
      " [  3.53535354e-01   1.17676768e+01]\n",
      " [  3.73737374e-01   1.18686869e+01]\n",
      " [  3.93939394e-01   1.19696970e+01]\n",
      " [  4.14141414e-01   1.20707071e+01]\n",
      " [  4.34343434e-01   1.21717172e+01]\n",
      " [  4.54545455e-01   1.22727273e+01]\n",
      " [  4.74747475e-01   1.23737374e+01]\n",
      " [  4.94949495e-01   1.24747475e+01]\n",
      " [  5.15151515e-01   1.25757576e+01]\n",
      " [  5.35353535e-01   1.26767677e+01]\n",
      " [  5.55555556e-01   1.27777778e+01]\n",
      " [  5.75757576e-01   1.28787879e+01]\n",
      " [  5.95959596e-01   1.29797980e+01]\n",
      " [  6.16161616e-01   1.30808081e+01]\n",
      " [  6.36363636e-01   1.31818182e+01]\n",
      " [  6.56565657e-01   1.32828283e+01]\n",
      " [  6.76767677e-01   1.33838384e+01]\n",
      " [  6.96969697e-01   1.34848485e+01]\n",
      " [  7.17171717e-01   1.35858586e+01]\n",
      " [  7.37373737e-01   1.36868687e+01]\n",
      " [  7.57575758e-01   1.37878788e+01]\n",
      " [  7.77777778e-01   1.38888889e+01]\n",
      " [  7.97979798e-01   1.39898990e+01]\n",
      " [  8.18181818e-01   1.40909091e+01]\n",
      " [  8.38383838e-01   1.41919192e+01]\n",
      " [  8.58585859e-01   1.42929293e+01]\n",
      " [  8.78787879e-01   1.43939394e+01]\n",
      " [  8.98989899e-01   1.44949495e+01]\n",
      " [  9.19191919e-01   1.45959596e+01]\n",
      " [  9.39393939e-01   1.46969697e+01]\n",
      " [  9.59595960e-01   1.47979798e+01]\n",
      " [  9.79797980e-01   1.48989899e+01]\n",
      " [  1.00000000e+00   1.50000000e+01]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-24dc4468d30c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mctr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCTRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mctr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabeled_pool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-f0c7ff71d090>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, Xs, y, p, n, unlabeled_pool_size, num_iter)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0my_hat1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munlabeled_pool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0my_hat2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munlabeled_pool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "n_neighbors = 3\n",
    "estimator1 = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "estimator2 = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "\n",
    "X1 = np.zeros((100,2))\n",
    "X1[:,0] = np.linspace(0,1,100)\n",
    "X1[:,1] = np.linspace(10,15,100)\n",
    "X2 = X1.copy()\n",
    "X2[:,0] = X2[:,0] + 0.1\n",
    "X2[:,1] = np.linspace(-100,-92,100)\n",
    "\n",
    "\n",
    "y = X1[:,0]\n",
    "\n",
    "y[np.arange(0,100,2)] = np.nan\n",
    "\n",
    "print(y)\n",
    "\n",
    "ctr = CTRegressor(random_state=2)\n",
    "ctr.fit([X1, X2], y, unlabeled_pool_size=10, num_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CTRegressor():\n",
    "    def __init__(\n",
    "                 self,\n",
    "                 estimator1=None,\n",
    "                 estimator2=None,\n",
    "                 k_neighbors = 3,\n",
    "                 random_state=0\n",
    "                 ):\n",
    "\n",
    "        # initialize a BaseCTEstimator object\n",
    "        #super().__init__(KNeighborsRegressor(n_neighbors=k_neighbors), KNeighborsRegressor(n_neighbors=k_neighbors), random_state)\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # if not given, set classifiers as gaussian naive bayes estimators\n",
    "        if estimator1 is None:\n",
    "            self.estimator1 = KNeighborsRegressor(n_neighbors=k_neighbors)\n",
    "        if estimator2 is None:\n",
    "            self.estimator2 = KNeighborsRegressor(n_neighbors=k_neighbors)\n",
    "\n",
    "        self.n_views_ = 2  # only 2 view learning supported currently\n",
    "\n",
    "        self.class_name = \"CTRegressor\"\n",
    "        \n",
    "        self.k_neighbors_ = 3\n",
    "\n",
    "    # requires Labeled sets for each view, U' shared by both views\n",
    "    def fit(\n",
    "            self,\n",
    "            Xs,\n",
    "            y,\n",
    "            p=1,\n",
    "            n=1,\n",
    "            unlabeled_pool_size=50,\n",
    "            num_iter=50\n",
    "            ):\n",
    "        # split data\n",
    "        # fit each estimator to Labeled set\n",
    "        # for num_iter:\n",
    "            # for each view:\n",
    "                # for each sample in U' for that view:\n",
    "                    # regress (y_hat = h(x))\n",
    "                    # find the k nearest examples in L to x (a set called Omega)\n",
    "                    # fit a new kNN to the labeled set with the addition of this sample\n",
    "                    # compute and store deltaMSE (MSE of the old regressor on each sample in Omega, minus MSE of new regressor on each sample in Omega)\n",
    "                # if there exists deltaMSE > 0\n",
    "                # then pick this example (and its regression) to add to the labeled set of other view, remove from U'\n",
    "            # if didn't add a new sample to either set, then exit\n",
    "\n",
    "        # final regressor = .5*h1(x) + h2(x)\n",
    "\n",
    "        print('here')\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self.p_, self.n_ = p, n\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        self.unlabeled_pool_size_ = unlabeled_pool_size\n",
    "        self.num_iter_ = num_iter\n",
    "\n",
    "        # extract the multiple views given\n",
    "        X1 = Xs[0]\n",
    "        X2 = Xs[1]\n",
    "\n",
    "        # the full set of unlabeled samples\n",
    "        U = [i for i, y_i in enumerate(y) if np.isnan(y_i)]\n",
    "        \n",
    "        # shuffle unlabeled_pool data for easy random access\n",
    "        np.random.shuffle(U)\n",
    "\n",
    "        # the small pool of unlabled samples to draw from in training\n",
    "        unlabeled_pool = U[-min(len(U), self.unlabeled_pool_size_):]\n",
    "        \n",
    "\n",
    "        # the labeled samples\n",
    "        L = [i for i, y_i in enumerate(y) if ~np.isnan(y_i)]\n",
    "\n",
    "        # remove the pool from overall unlabeled data\n",
    "        U = U[:-len(unlabeled_pool)]\n",
    "\n",
    "        it = 0\n",
    "        \n",
    "        print(\"starting\")\n",
    "        print(len(L))\n",
    "        print(len(U))\n",
    "        \n",
    "        while it < self.num_iter_ and U:\n",
    "            it += 1\n",
    "            \n",
    "            print(\"unlabeled pool\")\n",
    "            print(unlabeled_pool)\n",
    "            print(\"labeled\")\n",
    "            print(X1[L])\n",
    "\n",
    "            # fit each model to its respective view\n",
    "            self.estimator1.fit(X1[L], y[L])\n",
    "            self.estimator2.fit(X2[L], y[L])\n",
    "            \n",
    "            y_hat1 = self.estimator1.predict(X1[unlabeled_pool])\n",
    "            y_hat2 = self.estimator2.predict(X2[unlabeled_pool])\n",
    "            \n",
    "            neighbors1 = (self.estimator1.kneighbors(X1[unlabeled_pool], n_neighbors=self.k_neighbors_))[1]\n",
    "            neighbors2 = (self.estimator1.kneighbors(X2[unlabeled_pool], n_neighbors=self.k_neighbors_))[1]\n",
    "            \n",
    "            # find sample in each view which lowers the MSE the most\n",
    "            delta_MSE1 = []\n",
    "            for sample, (u, neigh) in enumerate(zip(unlabeled_pool, neighbors1)):\n",
    "                new_L = L.copy()\n",
    "                new_L.append(u)\n",
    "                new_y = np.concatenate((y[L].copy(), np.array(y_hat1[sample]).reshape(1,)))\n",
    "                new_estimator = KNeighborsRegressor(n_neighbors=self.k_neighbors_)\n",
    "                new_estimator.fit(X1[new_L], new_y)\n",
    "                delta_MSE1.append(self.estimate_delta_MSE_(self.estimator1, new_estimator, (X1[L])[neigh], (y[L])[neigh]))\n",
    "                print(delta_MSE1[-1])\n",
    "            \n",
    "            best_delta_idx = np.argmax(delta_MSE1)\n",
    "            now_labeled = []\n",
    "            add_labels = []\n",
    "            if delta_MSE1[best_delta_idx] > 0:\n",
    "                now_labeled.append(unlabeled_pool[best_delta_idx])\n",
    "                add_labels.append(y_hat1[best_delta_idx])\n",
    "                print(\"Added best from view 1\")\n",
    "            \n",
    "            delta_MSE2 = []\n",
    "            for sample, (u, neigh) in enumerate(zip(unlabeled_pool, neighbors2)):\n",
    "                new_L = L.copy()\n",
    "                new_L.append(u)\n",
    "                new_y = np.concatenate((y[L].copy(), np.array(y_hat2[sample]).reshape(1,)))\n",
    "                new_estimator = KNeighborsRegressor(n_neighbors=self.k_neighbors_)\n",
    "                new_estimator.fit(X2[new_L], new_y)\n",
    "#                 # debugging\n",
    "#                 if sample == 2:\n",
    "#                     delta_MSE2.append(2)\n",
    "#                 else:\n",
    "#                     delta_MSE2.append(.5)\n",
    "                delta_MSE2.append(self.estimate_delta_MSE_(self.estimator2, new_estimator, (X2[L])[neigh], (y[L])[neigh]))   \n",
    "            \n",
    "            # find top 2 in case overlap with view 1 selection\n",
    "            best_delta_idx = np.argsort(delta_MSE2)[-2:][::-1]\n",
    "            print(best_delta_idx)\n",
    "            if delta_MSE2[best_delta_idx[0]] > 0:\n",
    "                if best_delta_idx[0] not in now_labeled:\n",
    "                    print(\"adding best\")\n",
    "                    now_labeled.append(unlabeled_pool[best_delta_idx[0]])\n",
    "                    add_labels.append(y_hat1[best_delta_idx[0]])\n",
    "                elif best_delta_idx[1] > 0:\n",
    "                    print(\"adding second best because overlap\")\n",
    "                    now_labeled.append(unlabeled_pool[best_delta_idx[1]])\n",
    "                    add_labels.append(y_hat1[best_delta_idx[1]])\n",
    "            elif delta_MSE2[best_delta_idx[1]] > 0:\n",
    "                print(\"adding second best\")\n",
    "                now_labeled.append(unlabeled_pool[best_delta_idx[1]])\n",
    "                add_labels.append(y_hat1[best_delta_idx[1]])\n",
    "            \n",
    "            print(add_labels)\n",
    "            print(now_labeled)\n",
    "                    \n",
    "            # create new labels for new additions to the labeled group\n",
    "            for x, y_hat in zip(now_labeled, add_labels):\n",
    "                print(x)\n",
    "                y[x] = y_hat\n",
    "                L.extend([x])\n",
    "\n",
    "            # remove newly labeled samples from unlabeled_pool\n",
    "            unlabeled_pool = [elem for elem in unlabeled_pool\n",
    "                              if not (elem in now_labeled)]\n",
    "\n",
    "            # add new elements to unlabeled_pool\n",
    "            add_counter = 0\n",
    "            while add_counter != len(now_labeled) and U:\n",
    "                add_counter += 1\n",
    "                unlabeled_pool.append(U.pop())\n",
    "\n",
    "        print(\"ending\")\n",
    "        print(len(L))\n",
    "        print(len(U))\n",
    "        # fit the overall model on fully \"labeled\" data\n",
    "        self.estimator1.fit(X1[L], y[L])\n",
    "        self.estimator2.fit(X2[L], y[L])\n",
    "            \n",
    "    def estimate_delta_MSE_(self, old_estimator, new_estimator, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the decrease in MSE of the new estimator based on a small\n",
    "        sample of neighbors.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        old_estimator: estimator object\n",
    "            The current estimator trained on less data.\n",
    "        \n",
    "        new_estimator: estimator object\n",
    "            The new estimator trained with additional data.\n",
    "            \n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The truly labeled data that the old estimator was trained on.\n",
    "        \n",
    "        y : array-like, shape (n_samples,)\n",
    "            The labels for the samples in X.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        delta_MSE : float\n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # estimate the change in MSE\n",
    "        y_hat_old = old_estimator.predict(X)\n",
    "        y_hat_new = new_estimator.predict(X)\n",
    "        \n",
    "        print(\"errors\")\n",
    "        print(np.sum((y-y_hat_old)**2))\n",
    "        print(np.sum((y-y_hat_new)**2))\n",
    "        \n",
    "        return np.sum((y-y_hat_old)**2 - (y-y_hat_new)**2)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1]\n",
      "(2, 3)\n",
      "[0 1 2]\n",
      "[1 2 3]\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "xx = [-1,3,-2,5]\n",
    "print(np.argsort(xx)[-2:][::-1])\n",
    "xx = np.array([[0,1,2], [1,2,3]])\n",
    "print(xx.shape)\n",
    "for samp in xx:\n",
    "    print(samp)\n",
    "    \n",
    "y = np.zeros(10,)\n",
    "y2 = np.ones(10,)\n",
    "print(type(np.sum((y-y2)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
