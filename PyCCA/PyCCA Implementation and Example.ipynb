{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import dot, eye, ones, zeros\n",
    "import scipy.linalg\n",
    "from kernel_icd import kernel_icd\n",
    "from kernels import LinearKernel\n",
    "\n",
    "class KCCA(object):\n",
    "    \"\"\"An implementation of Kernel Canonical Correlation Analysis.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel1, kernel2, regularization, method = 'kettering_method',\n",
    "                 decomp = 'full', lrank = None,\n",
    "                 scaler1 = None,\n",
    "                 scaler2 = None,\n",
    "                 max_variance_ratio = 1.0):\n",
    "\n",
    "        if decomp not in ('full', 'icd'): #error handling\n",
    "            raise ValueError(\"Error: valid decom values are full or icd, received: \"+str(decomp))\n",
    "            \n",
    "        #initializing values inputted to class\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "        self.reg = regularization\n",
    "        self.method = getattr(self, decomp + \"_\" + method)\n",
    "            #getattr() returns value of named attribute\n",
    "            #equivalent to self.method = self.decomp+'_'+self.method\n",
    "\n",
    "        self.decomp = decomp\n",
    "        self.lrank = lrank\n",
    "\n",
    "        self.alpha1 = None\n",
    "        self.alpha2 = None\n",
    "        self.trainX1 = None\n",
    "        self.trainX2 = None\n",
    "        self.max_variance_rato = max_variance_ratio\n",
    "\n",
    "        if scaler1 is not None:\n",
    "            if hasattr(scaler1, \"transform\"):  #sklearn scaler\n",
    "                # hasattr returns true/false if variable has an attribute\n",
    "                self.scaler1 = scaler1.transform\n",
    "            else:  #assume callable function\n",
    "                self.scaler1 = scaler1\n",
    "        else:\n",
    "            self.scaler1 = None\n",
    "\n",
    "        if scaler2 is not None:\n",
    "            if hasattr(scaler2, \"transform\"):  #sklearn scaler\n",
    "                self.scaler2 = scaler2.transform\n",
    "            else:  #assume callable function\n",
    "                self.scaler2 = scaler2\n",
    "        else:\n",
    "            self.scaler2 = None\n",
    "\n",
    "    def full_standard_hardoon_method(self, K1, K2, reg):\n",
    "\n",
    "        N = K1.shape[0]\n",
    "        I = eye(N)\n",
    "        Z = numpy.zeros((N,N))\n",
    "\n",
    "        R1 = numpy.c_[Z, dot(K1, K2)]\n",
    "        R2 = numpy.c_[dot(K2, K1), Z]\n",
    "        R =  numpy.r_[R1, R2]\n",
    "\n",
    "        D1 = numpy.c_[dot(K1, K1 + reg*I), Z]\n",
    "        D2 = numpy.c_[Z, dot(K2, K2 + reg*I)]\n",
    "        D = 0.5*numpy.r_[D1, D2]\n",
    "\n",
    "        return (R, D)\n",
    "\n",
    "    def full_simplified_hardoon_method(self, K1, K2, reg):\n",
    "\n",
    "        N = K1.shape[0]\n",
    "        I = eye(N)\n",
    "        Z = numpy.zeros((N,N))\n",
    "\n",
    "        R1 = numpy.c_[Z, K2]\n",
    "        R2 = numpy.c_[K1, Z]\n",
    "        R =  numpy.r_[R1, R2]\n",
    "\n",
    "        D1 = numpy.c_[K1 + reg*I, Z]\n",
    "        D2 = numpy.c_[Z, K2 + reg*I]\n",
    "        D = numpy.r_[D1, D2]\n",
    "\n",
    "        return (R, D)\n",
    "\n",
    "    def full_kettering_method(self, K1, K2, reg):\n",
    "\n",
    "        N = K1.shape[0]\n",
    "        I = eye(N)\n",
    "        Z = numpy.zeros((N,N))\n",
    "\n",
    "        R1 = numpy.c_[K1, K2]\n",
    "        R2 = R1\n",
    "        R = 1./2 * numpy.r_[R1, R2]\n",
    "\n",
    "        D1 = numpy.c_[K1 + reg*I, Z]\n",
    "        D2 = numpy.c_[Z, K2 + reg*I]\n",
    "        D = numpy.r_[D1, D2]\n",
    "\n",
    "        return (R, D)\n",
    "\n",
    "    #def kcca(self, K1, K2):\n",
    "\n",
    "        ##remove the mean in features space\n",
    "        #N = K1.shape[0]\n",
    "        #N0 = eye(N) - 1./N * ones(N)\n",
    "\n",
    "        #if self.scaler1 is None:\n",
    "            #K1 = dot(dot(N0,K1),N0)\n",
    "        #if self.scaler2 is None:\n",
    "            #K2 = dot(dot(N0,K2),N0)\n",
    "\n",
    "        #R, D = self.method(K1, K2, self.reg)\n",
    "\n",
    "        ##solve generalized eigenvalues problem\n",
    "        #betas, alphas = scipy.linalg.eig(R,D)\n",
    "        #ind = numpy.argsort(numpy.real(betas))\n",
    "        #max_ind = ind[-1]\n",
    "        #alpha = alphas[:, max_ind]\n",
    "        #alpha = alpha/numpy.linalg.norm(alpha)\n",
    "        #beta = numpy.real(betas[max_ind])\n",
    "\n",
    "        #alpha1 = alpha[:N]\n",
    "        #alpha2 = alpha[N:]\n",
    "\n",
    "        #y1 = dot(K1, alpha1)\n",
    "        #y2 = dot(K2, alpha2)\n",
    "\n",
    "        #self.alpha1 = alpha1\n",
    "        #self.alpha2 = alpha2\n",
    "\n",
    "        #return (y1, y2, beta)\n",
    "        \n",
    "    #******* .fit calls kcca ********************\n",
    "    def kcca(self, K1, K2):\n",
    "        #K1 and K2 are the two linearkernels of the two dataviews\n",
    "\n",
    "        #remove the mean in features space\n",
    "        N = K1.shape[0]\n",
    "        N0 = eye(N) - 1./N * ones(N) #./ ensures division yields a float\n",
    "        \n",
    "        #scaler1 and scaler2 hold the datasets\n",
    "        if self.scaler1 is None:\n",
    "            K1 = dot(dot(N0,K1),N0)\n",
    "        if self.scaler2 is None:\n",
    "            K2 = dot(dot(N0,K2),N0)\n",
    "\n",
    "        R, D = self.method(K1, K2, self.reg) #calls one of the functions above\n",
    "\n",
    "        #solve generalized eigenvalues problem\n",
    "        betas, alphas = scipy.linalg.eig(R,D)\n",
    "\n",
    "        #sorting according to eigenvalue\n",
    "        betas =  numpy.real(betas)\n",
    "        ind = numpy.argsort(betas)\n",
    "        betas = betas[ind]\n",
    "        betas = betas[::-1]\n",
    "\n",
    "        #finding the components\n",
    "        if self.max_variance_rato < 1.0:\n",
    "            n_samples = len(betas)\n",
    "            explained_variance = (betas ** 2) / n_samples\n",
    "            explained_variance_ratio = explained_variance / explained_variance.sum()\n",
    "            ratio_cumsum = explained_variance_ratio.cumsum()\n",
    "            n_components = numpy.sum(ratio_cumsum < self.max_variance_rato) + 1\n",
    "        else:\n",
    "            #using all the dimensions\n",
    "            n_components = len(betas)\n",
    "            \n",
    "        alphas = alphas[:, ind]\n",
    "        alpha = alphas[:, :n_components]\n",
    "\n",
    "        #alpha = alpha/numpy.linalg.norm(alpha)\n",
    "        #making unit vectors\n",
    "        alpha = alpha / (numpy.sum(numpy.abs(alpha)**2 ,axis=0)**(1./2))\n",
    "\n",
    "        alpha1 = alpha[:N, :]\n",
    "        alpha2 = alpha[N:, :]\n",
    "\n",
    "        y1 = dot(K1, alpha1)\n",
    "        y2 = dot(K2, alpha2)\n",
    "\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "\n",
    "        return (y1, y2, betas[0])\n",
    "\n",
    "    def icd_simplified_hardoon_method(self, G1, G2, reg):\n",
    "        N1 = G1.shape[1]\n",
    "        N2 = G2.shape[1]\n",
    "\n",
    "        Z11 = zeros((N1, N1))\n",
    "        Z22 = zeros((N2, N2))\n",
    "        Z12 = zeros((N1,N2))\n",
    "\n",
    "        I11 = eye(N1)\n",
    "        I22 = eye(N2)\n",
    "\n",
    "        R1 = numpy.c_[Z11, dot(G1.T, G2)]\n",
    "        R2 = numpy.c_[dot(G2.T, G1), Z22]\n",
    "        R =  numpy.r_[R1, R2]\n",
    "\n",
    "        D1 = numpy.c_[dot(G1.T, G1) + reg*I11, Z12]\n",
    "        D2 = numpy.c_[Z12.T, dot(G2.T, G2) + reg*I22]\n",
    "        D = numpy.r_[D1, D2]\n",
    "\n",
    "        return (R, D)\n",
    "\n",
    "    def icd(self, G1, G2):\n",
    "        \"\"\"Incomplete Cholesky decomposition\n",
    "        \"\"\"\n",
    "\n",
    "        # remove mean. avoid standard calculation N0 = eye(N)-1/N*ones(N);\n",
    "        G1 = G1 - numpy.array(numpy.mean(G1, 0), ndmin=2, copy=False)\n",
    "        G2 = G2 - numpy.array(numpy.mean(G2, 0), ndmin=2, copy=False)\n",
    "\n",
    "        R, D = self.method(G1, G2, self.reg)\n",
    "\n",
    "        #solve generalized eigenvalues problem\n",
    "        betas, alphas = scipy.linalg.eig(R,D)\n",
    "        ind = numpy.argsort(numpy.real(betas))\n",
    "        max_ind = ind[-1]\n",
    "        alpha = alphas[:, max_ind]\n",
    "        alpha = alpha/numpy.linalg.norm(alpha)\n",
    "        beta = numpy.real(betas[max_ind])\n",
    "\n",
    "        N1 = G1.shape[1]\n",
    "        alpha1 = alpha[:N1]\n",
    "        alpha2 = alpha[N1:]\n",
    "\n",
    "        y1 = dot(G1, alpha1)\n",
    "        y2 = dot(G2, alpha2)\n",
    "\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "\n",
    "        return (y1, y2, beta)\n",
    "\n",
    "    #************ this is the function that will likely be called the most *********************\n",
    "    def fit(self, X1, X2):\n",
    "\n",
    "        if self.scaler1 is not None:\n",
    "            X1 = self.scaler1(X1) #scaler1 is a lambda function that copies the input\n",
    "        if self.scaler2 is not None:\n",
    "            X2 = self.scaler2(X2) #scaler2 does the same thing as scaler1\n",
    "        \n",
    "        #initialize training sets\n",
    "        self.trainX1 = X1\n",
    "        self.trainX2 = X2\n",
    "\n",
    "        if self.decomp == \"full\":\n",
    "            self.K1 = self.kernel1(X1, X1) #kernel1 is the linearkernel class\n",
    "            self.K2 = self.kernel2(X2, X2) #kernel2 is the linearkernel class\n",
    "            (y1, y2, beta) = self.kcca(self.K1, self.K2) #kcca function is called\n",
    "        else:\n",
    "            # get incompletely decomposed kernel matrices. K \\approx G*G'\n",
    "            self.K1 = kernel_icd(X1, self.kernel1,  self.lrank)\n",
    "            self.K2 = kernel_icd(X2, self.kernel2,  self.lrank)\n",
    "            (y1, y2, beta) = self.icd(self.K1, self.K2) #icd function is called\n",
    "\n",
    "        self.y1_ = y1\n",
    "        self.y2_ = y2\n",
    "        self.beta_ = beta\n",
    "        return self\n",
    "\n",
    "    def transform(self, X1 = None, X2 = None):\n",
    "        \"\"\"\n",
    "\n",
    "        Features centering taken from:\n",
    "        Scholkopf, B., Smola, A., & Muller, K. R. (1998).\n",
    "        Nonlinear component analysis as a kernel eigenvalue problem.\n",
    "        Neural computation, 10(5), 1299-1319.\n",
    "        \"\"\"\n",
    "        \n",
    "        rets = []\n",
    "        if X1 is not None:\n",
    "\n",
    "            if self.scaler1 is not None:\n",
    "                X1 = self.scaler1(X1)\n",
    "\n",
    "            Ktest = self.kernel1(X1, self.trainX1)\n",
    "            K = self.K1\n",
    "\n",
    "            if self.scaler1 is None:\n",
    "                L, M = Ktest.shape\n",
    "                ones_m = ones((M, M))\n",
    "                ones_mp = ones((L, M)) / M\n",
    "\n",
    "                #features centering\n",
    "                K1 = (Ktest - dot(ones_mp, K)\n",
    "                      - dot(Ktest, ones_m) + dot(dot(ones_mp, K), ones_m)\n",
    "                      )\n",
    "            else:\n",
    "                K1 = Ktest\n",
    "\n",
    "            res1 =  dot(K1, self.alpha1)\n",
    "            rets.append(res1)\n",
    "\n",
    "        if X2 is not None:\n",
    "\n",
    "            if self.scaler2 is not None:\n",
    "                X2 = self.scaler2(X2)\n",
    "\n",
    "            Ktest = self.kernel2(X2, self.trainX2)\n",
    "            K = self.K2\n",
    "\n",
    "            if self.scaler2 is None:\n",
    "                L, M = Ktest.shape\n",
    "                ones_m = ones((M, M))\n",
    "                ones_mp = ones((L, M)) / M\n",
    "\n",
    "                #features centering\n",
    "                K2 = (Ktest - dot(ones_mp, K)\n",
    "                      - dot(Ktest, ones_m) + dot(dot(ones_mp, K), ones_m)\n",
    "                      )\n",
    "            else:\n",
    "                K2 = Ktest\n",
    "\n",
    "            res2 =  dot(K2, self.alpha2)\n",
    "            rets.append(res2)\n",
    "\n",
    "        return rets\n",
    "\n",
    "def _mean_and_std(X, axis=0, with_mean=True, with_std=True):\n",
    "    \"\"\"Compute mean and std dev for centering, scaling\n",
    "\n",
    "    Zero valued std components are reset to 1.0 to avoid NaNs when scaling.\n",
    "    \"\"\"\n",
    "    X = numpy.asarray(X)\n",
    "    Xr = numpy.rollaxis(X, axis)\n",
    "\n",
    "    if with_mean:\n",
    "        mean_ = Xr.mean(axis=0)\n",
    "    else:\n",
    "        mean_ = None\n",
    "\n",
    "    if with_std:\n",
    "        std_ = Xr.std(axis=0)\n",
    "        if isinstance(std_, numpy.ndarray):\n",
    "            std_[std_ == 0.0] = 1.0\n",
    "        elif std_ == 0.:\n",
    "            std_ = 1.\n",
    "    else:\n",
    "        std_ = None\n",
    "\n",
    "    return mean_, std_\n",
    "\n",
    "class UnscaledKCCA(KCCA):\n",
    "    def __init__(self, kernel1, kernel2, regularization,\n",
    "                 method = 'kettering_method',\n",
    "                 max_variance_ratio = 1.0,\n",
    "                 ) :\n",
    "        super(UnscaledKCCA, self).__init__(kernel1, kernel2, regularization,\n",
    "                 method,\n",
    "                 'full', None,\n",
    "                 None,\n",
    "                 None,\n",
    "                 max_variance_ratio)\n",
    "\n",
    "        #this is to avoid pickling problems\n",
    "        self.method = method\n",
    "\n",
    "    def kcca(self, K1, K2):\n",
    "\n",
    "        method = getattr(self, \"full_\" + self.method)\n",
    "        R, D = method(K1, K2, self.reg)\n",
    "\n",
    "        #solve generalized eigenvalues problem\n",
    "        betas, alphas = scipy.linalg.eig(R,D)\n",
    "\n",
    "        #sorting according to eigenvalue\n",
    "        betas =  numpy.real(betas)\n",
    "        ind = numpy.argsort(betas)\n",
    "        betas = betas[ind]\n",
    "        betas = betas[::-1]\n",
    "\n",
    "        #fiding the components\n",
    "        n_samples = len(betas)\n",
    "        if self.max_variance_rato < 1.0:\n",
    "            explained_variance = (betas ** 2) / n_samples\n",
    "            explained_variance_ratio = explained_variance / explained_variance.sum()\n",
    "            ratio_cumsum = explained_variance_ratio.cumsum()\n",
    "            n_components = numpy.sum(ratio_cumsum < self.max_variance_rato) + 1\n",
    "        else:\n",
    "            #using all the dimensions\n",
    "            n_components = n_samples\n",
    "\n",
    "        alphas = alphas[:, ind]\n",
    "        alpha = alphas[:, :n_components]\n",
    "\n",
    "        #alpha = alpha/numpy.linalg.norm(alpha)\n",
    "        #making unit vectors\n",
    "        alpha = alpha / (numpy.sum(numpy.abs(alpha)**2 ,axis=0)**(1./2))\n",
    "\n",
    "        N = K1.shape[0]\n",
    "        alpha1 = alpha[:N, :] #up to shape of K1\n",
    "        alpha2 = alpha[N:, :] #remainder of alpha\n",
    "\n",
    "        y1 = dot(K1, alpha1)\n",
    "        y2 = dot(K2, alpha2)\n",
    "\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.y1_ = y1 #dot product of K1 and alpha1\n",
    "        self.y2_ = y2\n",
    "        self.beta_ = betas[0]\n",
    "        self.betas_ = betas\n",
    "\n",
    "        return (y1, y2, betas[0])\n",
    "\n",
    "    def fit(self, X1, X2, K1_args = None, K2_args=None):\n",
    "        self.trainX1 = X1\n",
    "        self.trainX2 = X2\n",
    "\n",
    "        if K1_args is not None:\n",
    "            self.K1 = self.kernel1(X1, X1, K1_args)\n",
    "        else:\n",
    "            self.K1 = self.kernel1(X1, X1)\n",
    "        if K2_args is not None:\n",
    "            self.K2 = self.kernel2(X2, X2, K2_args)\n",
    "        else:\n",
    "            self.K2 = self.kernel2(X2, X2)\n",
    "        (y1, y2, beta) = self.kcca(self.K1, self.K2)\n",
    "\n",
    "        self.y1_ = y1\n",
    "        self.y2_ = y2\n",
    "        self.beta_ = beta\n",
    "        return self\n",
    "\n",
    "    def transform(self, X1 = None, X2 = None,\n",
    "                  n_dims_frac = 0.1,\n",
    "                  K1_args = None,\n",
    "                  K2_args = None,):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        rets = []\n",
    "        if X1 is not None:\n",
    "            if type(n_dims_frac) is float:\n",
    "                n_dims = numpy.ceil(n_dims_frac * self.alpha1.shape[1])\n",
    "            else:\n",
    "                n_dims = n_dims_frac\n",
    "            if K1_args is not None:\n",
    "                Ktest = self.kernel1(X1, self.trainX1, K1_args)\n",
    "            else:\n",
    "                Ktest = self.kernel1(X1, self.trainX1)\n",
    "\n",
    "            res1 =  dot(Ktest, self.alpha1[:, :n_dims])\n",
    "            rets.append(res1)\n",
    "\n",
    "        if X2 is not None:\n",
    "            if type(n_dims_frac) is float:\n",
    "                n_dims = numpy.ceil(n_dims_frac * self.alpha2.shape[1])\n",
    "            else:\n",
    "                n_dims = n_dims_frac\n",
    "            if K2_args is not None:\n",
    "                Ktest = self.kernel2(X2, self.trainX2, K2_args)\n",
    "            else:\n",
    "                Ktest = self.kernel2(X2, self.trainX2)\n",
    "            K2 = self.K2\n",
    "\n",
    "            res2 =  dot(Ktest, self.alpha2[:, :n_dims])\n",
    "            rets.append(res2)\n",
    "\n",
    "        return rets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  0.9999999911541163\n",
      "Trying to test\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theodorelee/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py:591: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12667d898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12660aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = numpy.random.rand(200, 100) #100 x 20 matrix with rand values between 0 and 1\n",
    "x2 = numpy.random.rand(200, 150) #100 x 30 matrix with rand values between 0 and 1\n",
    "kernel = LinearKernel() #initialize a linear kernel class\n",
    "cca = KCCA(kernel, kernel,\n",
    "                regularization=1e-5,\n",
    "                decomp='full',\n",
    "                method='kettering_method',\n",
    "                scaler1=lambda x:x,\n",
    "                scaler2=lambda x:x).fit(x1,x2)\n",
    "#fitting finds the optimal canonical vectors to maximize the correlation of variates\n",
    "\n",
    "print(\"Done \",  cca.beta_) #prints the highest beta for the first variate\n",
    "#beta is the correlation coefficient between variates\n",
    "\n",
    "orig_y1 = cca.y1_ #dot product of K1 and alpha1\n",
    "orig_y2 = cca.y2_ #dot product of K2 and alpha2\n",
    "\n",
    "print(\"Trying to test\")\n",
    "y1, y2 = cca.transform(x1, x2) # calls transform\n",
    "print(numpy.allclose(y1, orig_y1))\n",
    "print(numpy.allclose(y2, orig_y2))\n",
    "\n",
    "#Graphing the variates- not sure what exactly im viewing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(y1,y2)\n",
    "plt.xlabel('Canonical Variate 1')\n",
    "plt.ylabel('Canonical Variate 2')\n",
    "plt.title('Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
